# AI Acceptable Use Policy

> **"AI is a force multiplier for engineering excellenceâ€”when used responsibly."**

This policy defines how our engineering teams may use AI tools while protecting intellectual property, maintaining security, and ensuring ethical application.

---

## Scope

This policy applies to:
- All engineering team members
- All AI-powered tools (GitHub Copilot, ChatGPT, Claude, Cursor, etc.)
- All work-related activities (coding, documentation, analysis)

---

## Guiding Principles

| Principle | Description |
|:---|:---|
| **Human Oversight** | AI assists; humans decide |
| **Data Protection** | Never expose sensitive data to AI |
| **Quality Assurance** | AI output must be reviewed and tested |
| **Transparency** | Disclose AI usage when relevant |
| **Continuous Learning** | Stay current on AI capabilities and risks |

---

## Approved Use Cases

### Allowed

| Use Case | Guidance |
|:---|:---|
| **Code Generation** | Boilerplate, utilities, standard patterns |
| **Code Review Assistance** | Identifying bugs, suggesting improvements |
| **Documentation** | READMEs, comments, API docs |
| **Test Generation** | Unit tests, test data, edge cases |
| **Learning & Research** | Understanding new technologies, debugging |
| **Refactoring** | Code cleanup, performance optimization |
| **Translation** | Converting between languages/frameworks |

### Allowed with Caution

| Use Case | Required Precautions |
|:---|:---|
| **Security-Related Code** | Mandatory human security review |
| **Database Queries** | Review for injection risks, performance |
| **Infrastructure Code** | Peer review before apply |
| **Customer-Facing Content** | Legal/Marketing approval |

### Prohibited

| Use Case | Reason |
|:---|:---|
| **Inputting Customer PII** | Privacy violation, data breach risk |
| **Inputting Credentials/Secrets** | Security risk |
| **Inputting Proprietary Algorithms** | IP protection |
| **Generating Legal/Compliance Docs** | Requires qualified review |
| **Autonomous Deployments** | Human approval required |
| **Performance Reviews/HR Decisions** | Ethical and legal concerns |

---

## Data Protection Rules

### Never Input to AI Tools

```
âŒ Customer data (names, emails, addresses, payment info)
âŒ API keys, tokens, passwords, secrets
âŒ Internal financial data
âŒ Unreleased product specifications
âŒ Legal documents or contracts
âŒ Employee personal information
âŒ Security vulnerabilities (before patch)
```

### Safe to Input

```
âœ… Public documentation and tutorials
âœ… Open-source code snippets
âœ… Generic coding questions
âœ… Anonymized/synthetic data
âœ… Published API documentation
âœ… General architectural patterns
```

### Data Sanitization Checklist

Before pasting code into AI tools:

- [ ] Remove all hardcoded credentials
- [ ] Replace real customer IDs with placeholders
- [ ] Strip comments containing sensitive business logic
- [ ] Remove internal URLs and endpoints
- [ ] Anonymize any personal information

---

## Quality Assurance Requirements

### All AI-Generated Code Must:

1. **Pass Code Review** â€” Same standards as human-written code
2. **Pass All Tests** â€” Unit, integration, and E2E where applicable
3. **Pass Security Scans** â€” SAST/DAST tools, dependency checks
4. **Pass Linting** â€” Style and formatting standards
5. **Be Understood** â€” Author must explain what it does

### The "Explain It" Rule

> **If you can't explain the AI-generated code to a teammate, don't merge it.**

AI can produce plausible-looking code that contains subtle bugs. You are responsible for understanding and validating every line.

---

## Intellectual Property

### Ownership

- AI-assisted code created during work belongs to the company
- You remain the author and are accountable for quality
- AI tools are instruments, like IDEs or compilers

### License Compliance

| Concern | Mitigation |
|:---|:---|
| **Training Data Origins** | Use enterprise AI tools with indemnification |
| **Open Source Licenses** | Scan generated code for license conflicts |
| **Copyright Claims** | Document AI usage for legal defensibility |

### Disclosure Requirements

| Situation | Disclosure Needed |
|:---|:---|
| Internal code | Not required |
| Open source contributions | Check project policy |
| Client deliverables | Per contract terms |
| Patents/IP filings | Mandatory disclosure |

---

## Security Requirements

### Tool Approval

Only use AI tools approved by Security/IT:

| Status | Tools |
|:---|:---|
| **Approved** | [List approved tools here] |
| **Under Review** | [List tools being evaluated] |
| **Prohibited** | [List banned tools] |

### Configuration Requirements

- Enable enterprise SSO where available
- Disable training on company data (opt-out)
- Use private/business tiers, not personal accounts
- Enable audit logging where available

### Incident Reporting

If you accidentally expose sensitive data to an AI tool:

1. **Stop** â€” Don't input more data
2. **Report** â€” Notify Security immediately
3. **Document** â€” Record what was exposed
4. **Remediate** â€” Rotate credentials if applicable

---

## Accountability

### Individual Responsibility

You are accountable for:
- What you input to AI tools
- The quality of AI-generated output you use
- Understanding the code you commit
- Following this policy

### Manager Responsibility

Managers must:
- Ensure team understands this policy
- Review AI usage during code reviews
- Escalate policy violations
- Provide training resources

---

## Violations

| Severity | Example | Consequence |
|:---|:---|:---|
| **Minor** | Using unapproved tool for non-sensitive task | Coaching, policy review |
| **Moderate** | Insufficient review of AI-generated code | Formal warning, training |
| **Severe** | Exposing customer PII to AI tool | Disciplinary action |
| **Critical** | Exposing credentials, causing breach | Termination possible |

---

## Policy Updates

This policy will be reviewed quarterly as AI capabilities evolve. Significant changes will be communicated via:
- Engineering All-Hands
- Slack #engineering-announcements
- Email notification

**Last Updated:** [Date]
**Next Review:** [Date + 3 months]
**Owner:** Engineering Leadership

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI ACCEPTABLE USE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  âœ… DO                          âŒ DON'T                    â”‚
â”‚  â”€â”€â”€â”€â”€                          â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Generate boilerplate         â€¢ Input customer data       â”‚
â”‚  â€¢ Write tests                  â€¢ Input credentials         â”‚
â”‚  â€¢ Draft documentation          â€¢ Input proprietary code    â”‚
â”‚  â€¢ Debug with sanitized code    â€¢ Trust output blindly      â”‚
â”‚  â€¢ Learn new technologies       â€¢ Skip code review          â”‚
â”‚                                                             â”‚
â”‚  ğŸ”’ ALWAYS                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  â€¢ Sanitize inputs              â€¢ Review all output         â”‚
â”‚  â€¢ Use approved tools           â€¢ Understand before merge   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

<sub>**Management & Culture** | Vadym Shukurov</sub>
